{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCAF - Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives a example for SCAF. We run through training word embedding models, building the time series model and running the change detection.\n",
    "\n",
    "#### Setup \n",
    "We use the small [LeeCorpus](http://faculty.sites.uci.edu/mdlee/similarity-data/) and have removed any special characters, punctuation and numbers. We have duplicated the corpus 10 times and perturb the last 5 versions by replacing every second word \"the\" with \"in\". Afterwards we have convert the full text to the [Google Ngram format](http://storage.googleapis.com/books/ngrams/books/datasetsv2.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 22:21:37,307 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from scaf.data import DataStore\n",
    "from scaf.jobs import Training, BuildTimeseries, ChangeDetectionJob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify paths to corpus and output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../scaf/tests/test_data'\n",
    "# Original corpus files, ngrams and frequency files\n",
    "data_file = lambda file_name: os.path.join(file_path, file_name)\n",
    "orig_corpus_files = ['lee.ngrams', 'lee_modified.ngrams']\n",
    "orig_corpus_freq_files = ['lee.freq', 'lee_modified.freq']\n",
    "# Learned corpora\n",
    "corpus_path = os.path.join(file_path, 'corpus')\n",
    "corpus_file = lambda file_name: os.path.join(corpus_path, file_name)\n",
    "# Output directory for embeddings, store and change detection\n",
    "output_path = os.path.join(file_path, 'output')\n",
    "output_file = lambda file_name: os.path.join(output_path, file_name)\n",
    "\n",
    "# Modified word\n",
    "CHANGED_WORD = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean previous files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in [corpus_path, output_path]:\n",
    "    if os.path.exists(f):\n",
    "        shutil.rmtree(f)\n",
    "    os.makedirs(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn 10 embedding models for time periods $1,2,3 \\dots, 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_config = {\n",
    "    'input': '',\n",
    "    'output': '',\n",
    "    'corpus_building_mode': 'ignore',\n",
    "    'gensim_params': {\n",
    "        'size': 25,\n",
    "        'sg': 1,\n",
    "        'negative': 5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(corpus):\n",
    "    embedding_config['input'] = corpus_file('{}'.format(i))\n",
    "    embedding_config['output_path'] = output_path\n",
    "    t = Training(embedding_config)\n",
    "    t.execute()\n",
    "    return os.path.join(output_file(corpus), '{}_model'.format(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 22:21:37,564 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:37,565 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:37,567 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:37,571 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:37,584 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:37,586 : INFO : Loading a fresh vocabulary\n",
      "2019-03-20 22:21:37,590 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:37,592 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:37,602 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:37,603 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:37,603 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:37,605 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n",
      "2019-03-20 22:21:37,609 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:37,632 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:37,632 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:37,655 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:37,656 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:37,656 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:37,657 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:37,658 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:37,662 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:37,663 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:37,664 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:37,664 : INFO : training on 18540 raw words (2249 effective words) took 0.0s, 77949 effective words/s\n",
      "2019-03-20 22:21:37,665 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:37,665 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:37,666 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:37,688 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:37,689 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:37,690 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:37,690 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:37,691 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:37,692 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:37,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:37,693 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:37,694 : INFO : training on 18540 raw words (2183 effective words) took 0.0s, 85965 effective words/s\n",
      "2019-03-20 22:21:37,695 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:37,714 : INFO : [TRAIN] Current distance is 0.9999996428040866.\n",
      "2019-03-20 22:21:37,715 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:37,716 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/1/1_model\n",
      "2019-03-20 22:21:37,742 : INFO : [TRAIN] Export finished.\n",
      "2019-03-20 22:21:37,743 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:37,745 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:37,745 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:37,746 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:37,760 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:37,761 : INFO : Loading a fresh vocabulary\n",
      "2019-03-20 22:21:37,764 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:37,765 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:37,777 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:37,778 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:37,779 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:37,780 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n",
      "2019-03-20 22:21:37,783 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:37,810 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:37,811 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:37,832 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:37,835 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:37,836 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:37,837 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:37,838 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:37,840 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:37,840 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:37,844 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:37,844 : INFO : training on 18540 raw words (2249 effective words) took 0.0s, 72920 effective words/s\n",
      "2019-03-20 22:21:37,845 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:37,845 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:37,846 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:37,870 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:37,871 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:37,872 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:37,873 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:37,873 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:37,874 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:37,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:37,875 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:37,875 : INFO : training on 18540 raw words (2183 effective words) took 0.0s, 93327 effective words/s\n",
      "2019-03-20 22:21:37,876 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:37,898 : INFO : [TRAIN] Current distance is 0.9999996428040866.\n",
      "2019-03-20 22:21:37,900 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:37,901 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/2/2_model\n",
      "2019-03-20 22:21:37,927 : INFO : [TRAIN] Export finished.\n",
      "2019-03-20 22:21:37,929 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:37,930 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:37,931 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:37,932 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:37,945 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:37,947 : INFO : Loading a fresh vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 22:21:37,950 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:37,951 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:37,963 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:37,964 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:37,964 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:37,965 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n",
      "2019-03-20 22:21:37,972 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:38,000 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:38,001 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,029 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,031 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,032 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:38,033 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,034 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,034 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,035 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,036 : INFO : training on 18540 raw words (2249 effective words) took 0.0s, 88790 effective words/s\n",
      "2019-03-20 22:21:38,037 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,037 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:38,039 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,067 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,068 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,069 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:38,070 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,071 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,072 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,072 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,074 : INFO : training on 18540 raw words (2183 effective words) took 0.0s, 79845 effective words/s\n",
      "2019-03-20 22:21:38,075 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,095 : INFO : [TRAIN] Current distance is 0.9999996428040866.\n",
      "2019-03-20 22:21:38,096 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:38,097 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/3/3_model\n",
      "2019-03-20 22:21:38,121 : INFO : [TRAIN] Export finished.\n",
      "2019-03-20 22:21:38,123 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:38,124 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:38,124 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:38,125 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:38,138 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:38,140 : INFO : Loading a fresh vocabulary\n",
      "2019-03-20 22:21:38,143 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:38,144 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:38,156 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:38,157 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:38,158 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:38,158 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n",
      "2019-03-20 22:21:38,162 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:38,185 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:38,186 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,215 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,217 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,218 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:38,219 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,220 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,220 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,221 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,222 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,222 : INFO : training on 18540 raw words (2249 effective words) took 0.0s, 82507 effective words/s\n",
      "2019-03-20 22:21:38,223 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,224 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:38,224 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,245 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,247 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,248 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:38,250 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,251 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,251 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,252 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,253 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,253 : INFO : training on 18540 raw words (2183 effective words) took 0.0s, 82939 effective words/s\n",
      "2019-03-20 22:21:38,254 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,273 : INFO : [TRAIN] Current distance is 0.9999996428040866.\n",
      "2019-03-20 22:21:38,274 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:38,277 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/4/4_model\n",
      "2019-03-20 22:21:38,304 : INFO : [TRAIN] Export finished.\n",
      "2019-03-20 22:21:38,318 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:38,319 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:38,321 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:38,327 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:38,341 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:38,346 : INFO : Loading a fresh vocabulary\n",
      "2019-03-20 22:21:38,349 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:38,350 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:38,362 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:38,363 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:38,364 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:38,365 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 22:21:38,369 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:38,393 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:38,394 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,414 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,421 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,422 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:38,422 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,423 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,424 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,424 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,425 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,426 : INFO : training on 18540 raw words (2249 effective words) took 0.0s, 80971 effective words/s\n",
      "2019-03-20 22:21:38,426 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,427 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:38,428 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,448 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,457 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,460 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:38,462 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,465 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,466 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,469 : INFO : training on 18540 raw words (2183 effective words) took 0.0s, 56359 effective words/s\n",
      "2019-03-20 22:21:38,470 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,490 : INFO : [TRAIN] Current distance is 0.9999996428040866.\n",
      "2019-03-20 22:21:38,491 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:38,493 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/5/5_model\n",
      "2019-03-20 22:21:38,518 : INFO : [TRAIN] Export finished.\n",
      "2019-03-20 22:21:38,520 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:38,521 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:38,522 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:38,523 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:38,536 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:38,537 : INFO : Loading a fresh vocabulary\n",
      "2019-03-20 22:21:38,543 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:38,544 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:38,556 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:38,557 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:38,558 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:38,559 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n",
      "2019-03-20 22:21:38,563 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:38,589 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:38,590 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,612 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,614 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,614 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:38,615 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,616 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,616 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,618 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,619 : INFO : training on 18540 raw words (2213 effective words) took 0.0s, 85961 effective words/s\n",
      "2019-03-20 22:21:38,619 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,620 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:38,621 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,643 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,645 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,646 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:38,646 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,647 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,650 : INFO : training on 18540 raw words (2173 effective words) took 0.0s, 83202 effective words/s\n",
      "2019-03-20 22:21:38,651 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,672 : INFO : [TRAIN] Current distance is 0.9999995934045577.\n",
      "2019-03-20 22:21:38,673 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:38,674 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/6/6_model\n",
      "2019-03-20 22:21:38,699 : INFO : [TRAIN] Export finished.\n",
      "2019-03-20 22:21:38,700 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:38,701 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:38,703 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:38,703 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:38,718 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:38,719 : INFO : Loading a fresh vocabulary\n",
      "2019-03-20 22:21:38,724 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:38,726 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:38,737 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:38,738 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:38,739 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:38,740 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n",
      "2019-03-20 22:21:38,744 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:38,770 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:38,771 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,791 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,793 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,794 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 22:21:38,795 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,796 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,796 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,797 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,798 : INFO : training on 18540 raw words (2213 effective words) took 0.0s, 102148 effective words/s\n",
      "2019-03-20 22:21:38,799 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,800 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:38,800 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:38,858 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:38,859 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:38,860 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:38,861 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:38,866 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:38,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:38,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:38,868 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:38,869 : INFO : training on 18540 raw words (2173 effective words) took 0.1s, 32910 effective words/s\n",
      "2019-03-20 22:21:38,871 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:38,891 : INFO : [TRAIN] Current distance is 0.9999995934045577.\n",
      "2019-03-20 22:21:38,891 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:38,892 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/7/7_model\n",
      "2019-03-20 22:21:38,917 : INFO : [TRAIN] Export finished.\n",
      "2019-03-20 22:21:38,918 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:38,919 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:38,921 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:38,921 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:38,934 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:38,935 : INFO : Loading a fresh vocabulary\n",
      "2019-03-20 22:21:38,939 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:38,940 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:38,951 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:38,952 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:38,953 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:38,954 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n",
      "2019-03-20 22:21:38,958 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:38,985 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:38,986 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:39,009 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:39,012 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:39,014 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:39,016 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:39,019 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:39,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:39,021 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:39,022 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:39,022 : INFO : training on 18540 raw words (2213 effective words) took 0.0s, 67389 effective words/s\n",
      "2019-03-20 22:21:39,023 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:39,024 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:39,025 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:39,045 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:39,047 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:39,048 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:39,048 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:39,049 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:39,050 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:39,051 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:39,052 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:39,052 : INFO : training on 18540 raw words (2173 effective words) took 0.0s, 86014 effective words/s\n",
      "2019-03-20 22:21:39,053 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:39,075 : INFO : [TRAIN] Current distance is 0.9999995934045577.\n",
      "2019-03-20 22:21:39,076 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:39,077 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/8/8_model\n",
      "2019-03-20 22:21:39,101 : INFO : [TRAIN] Export finished.\n",
      "2019-03-20 22:21:39,103 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:39,104 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:39,105 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:39,106 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:39,120 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:39,121 : INFO : Loading a fresh vocabulary\n",
      "2019-03-20 22:21:39,127 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:39,128 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:39,140 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:39,141 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:39,142 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:39,143 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n",
      "2019-03-20 22:21:39,147 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:39,172 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:39,174 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:39,199 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:39,201 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:39,202 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:39,203 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:39,204 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:39,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:39,205 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:39,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:39,207 : INFO : training on 18540 raw words (2213 effective words) took 0.0s, 72081 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 22:21:39,208 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:39,209 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:39,209 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:39,231 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:39,233 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:39,234 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:39,235 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:39,236 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:39,236 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:39,237 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:39,238 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:39,239 : INFO : training on 18540 raw words (2173 effective words) took 0.0s, 81818 effective words/s\n",
      "2019-03-20 22:21:39,239 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:39,263 : INFO : [TRAIN] Current distance is 0.9999995934045577.\n",
      "2019-03-20 22:21:39,264 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:39,265 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/9/9_model\n",
      "2019-03-20 22:21:39,289 : INFO : [TRAIN] Export finished.\n",
      "2019-03-20 22:21:39,291 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-20 22:21:39,292 : INFO : [TRAIN] Start building corpus.\n",
      "2019-03-20 22:21:39,293 : INFO : collecting all words and their counts\n",
      "2019-03-20 22:21:39,294 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-20 22:21:39,308 : INFO : collected 1580 word types from a corpus of 18540 raw words and 3708 sentences\n",
      "2019-03-20 22:21:39,310 : INFO : Loading a fresh vocabulary\n",
      "2019-03-20 22:21:39,314 : INFO : min_count=1 retains 1580 unique words (100% of original 1580, drops 0)\n",
      "2019-03-20 22:21:39,315 : INFO : min_count=1 leaves 18540 word corpus (100% of original 18540, drops 0)\n",
      "2019-03-20 22:21:39,327 : INFO : deleting the raw counts dictionary of 1580 items\n",
      "2019-03-20 22:21:39,329 : INFO : sample=1e-05 downsamples 1580 most-common words\n",
      "2019-03-20 22:21:39,329 : INFO : downsampling leaves estimated 2226 word corpus (12.0% of prior 18540)\n",
      "2019-03-20 22:21:39,330 : INFO : estimated required memory for 1580 words and 25 dimensions: 1106000 bytes\n",
      "2019-03-20 22:21:39,335 : INFO : resetting layer weights\n",
      "2019-03-20 22:21:39,359 : INFO : [TRAIN] Training epoch 1.\n",
      "2019-03-20 22:21:39,360 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:39,384 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:39,386 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:39,387 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:39,393 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:39,397 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:39,398 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:39,399 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:39,400 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:39,401 : INFO : training on 18540 raw words (2213 effective words) took 0.0s, 61703 effective words/s\n",
      "2019-03-20 22:21:39,402 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:39,403 : INFO : [TRAIN] Training epoch 2.\n",
      "2019-03-20 22:21:39,403 : INFO : training model with 8 workers on 1580 vocabulary and 25 features, using sg=1 hs=0 sample=1e-05 negative=5 window=4\n",
      "2019-03-20 22:21:39,426 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-20 22:21:39,428 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-20 22:21:39,430 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-20 22:21:39,431 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-20 22:21:39,436 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-20 22:21:39,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-20 22:21:39,438 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-20 22:21:39,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-20 22:21:39,441 : INFO : training on 18540 raw words (2173 effective words) took 0.0s, 63788 effective words/s\n",
      "2019-03-20 22:21:39,444 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-03-20 22:21:39,463 : INFO : [TRAIN] Current distance is 0.9999995934045577.\n",
      "2019-03-20 22:21:39,464 : INFO : [TRAIN] Training finished. Writing output file.\n",
      "2019-03-20 22:21:39,465 : INFO : storing 1580x25 projection weights into ../scaf/tests/test_data/output/10/10_model\n",
      "2019-03-20 22:21:39,492 : INFO : [TRAIN] Export finished.\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "# 5 times cleaned lee corpus\n",
    "for i in range(1, 6):\n",
    "    f = corpus_file('{}'.format(i))\n",
    "    shutil.copyfile(data_file(orig_corpus_files[0]), f)\n",
    "    model_file = train_model('{}'.format(i))\n",
    "    models.append(model_file)\n",
    "# 5 times perturbed and cleaned lee corpus\n",
    "for i in range(6, 11):\n",
    "    f = corpus_file('{}'.format(i))\n",
    "    shutil.copyfile(data_file(orig_corpus_files[1]), f)\n",
    "    model_file = train_model('{}'.format(i))\n",
    "    models.append(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine the word embedding information with frequency information and build a store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../scaf/tests/test_data/output/1/1_model',\n",
       " '../scaf/tests/test_data/output/2/2_model',\n",
       " '../scaf/tests/test_data/output/3/3_model',\n",
       " '../scaf/tests/test_data/output/4/4_model',\n",
       " '../scaf/tests/test_data/output/5/5_model',\n",
       " '../scaf/tests/test_data/output/6/6_model',\n",
       " '../scaf/tests/test_data/output/7/7_model',\n",
       " '../scaf/tests/test_data/output/8/8_model',\n",
       " '../scaf/tests/test_data/output/9/9_model',\n",
       " '../scaf/tests/test_data/output/10/10_model']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We align the embedding with Procrustes analysis. Then we similarity time series by computing the cosine similarity of consecutive embeddings for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 22:21:39,518 : INFO : [BUILD_TS] Starting building time series.\n",
      "2019-03-20 22:21:39,519 : INFO : [BUILD_TS] Loading embeddings.\n",
      "2019-03-20 22:21:39,958 : INFO : [BUILD_TS] Finished loading embeddings.\n",
      "2019-03-20 22:21:39,960 : INFO : [BUILD_TS] Starting alignment.\n",
      "2019-03-20 22:21:39,960 : INFO : [ALIGN] Starting alignment with mode procrustes\n",
      "2019-03-20 22:21:39,971 : INFO : [ALIGN] Status 0.0%\n",
      "2019-03-20 22:21:39,985 : INFO : [ALIGN] Status 11.11111111111111%\n",
      "2019-03-20 22:21:39,996 : INFO : [ALIGN] Status 22.22222222222222%\n",
      "2019-03-20 22:21:40,010 : INFO : [ALIGN] Status 33.33333333333333%\n",
      "2019-03-20 22:21:40,022 : INFO : [ALIGN] Status 44.44444444444444%\n",
      "2019-03-20 22:21:40,033 : INFO : [ALIGN] Status 55.55555555555556%\n",
      "2019-03-20 22:21:40,044 : INFO : [ALIGN] Status 66.66666666666666%\n",
      "2019-03-20 22:21:40,056 : INFO : [ALIGN] Status 77.77777777777779%\n",
      "2019-03-20 22:21:40,071 : INFO : [ALIGN] Status 88.88888888888889%\n",
      "2019-03-20 22:21:40,094 : INFO : [ALIGN] Status 100%\n",
      "2019-03-20 22:21:40,097 : INFO : [BUILD_TS] Finished alignment.\n",
      "2019-03-20 22:21:40,198 : INFO : [BUILD_TS] Storing time series in '../scaf/tests/test_data/output/sim.ts'\n",
      "2019-03-20 22:21:40,251 : INFO : [BUILD_TS] Finished building time series.\n"
     ]
    }
   ],
   "source": [
    "b = BuildTimeseries(models, output_file=output_file('sim.ts'), alignment_mode='procrustes')\n",
    "b.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build frequency time series from original frequency files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    word word_type   1   2   3   4   5   6   7   8   9  10\n",
      "784    a         X  84  84  84  84  84  84  84  84  84  84\n",
      "    word word_type   1   2   3   4   5    6    7    8    9   10\n",
      "953   in         X  93  93  93  93  93  247  247  247  247  247\n"
     ]
    }
   ],
   "source": [
    "original = pd.read_csv(data_file(orig_corpus_freq_files[0]), sep='\\t',\n",
    "                       names=('word', 'year', 'match_count', 'volume_count'), quoting=3)\n",
    "modified = pd.read_csv(data_file(orig_corpus_freq_files[1]), sep='\\t',\n",
    "                       names=('word', 'year', 'match_count', 'volume_count'), quoting=3)\n",
    "merged = original[['word', 'match_count']].join(modified[['word', 'match_count']].set_index('word'),\n",
    "                                                on='word', rsuffix='_b')\n",
    "merged['word_type'] = 'X'\n",
    "for i in range(1, 6):\n",
    "    merged[str(i)] = merged['match_count']\n",
    "for i in range(6, 11):\n",
    "    merged[str(i)] = merged['match_count_b']\n",
    "del merged['match_count']\n",
    "del merged['match_count_b']\n",
    "merged.to_csv(output_file('freq.ts'), index=False, quoting=3, header=None)\n",
    "\n",
    "# Print series for the unperturbed word 'a' and the perturbed word 'in'\n",
    "print(merged[merged['word'] == 'a'])\n",
    "print(merged[merged['word'] == 'in'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally build data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 22:21:40,327 : INFO : Start bulding temp dict\n",
      "2019-03-20 22:21:40,759 : INFO : Finished building temp dict\n",
      "2019-03-20 22:21:40,761 : INFO : Start building final store\n",
      "2019-03-20 22:21:41,149 : INFO : Finished building final store\n"
     ]
    }
   ],
   "source": [
    "store = DataStore()\n",
    "store.load_data(output_file('sim.ts'), output_file('freq.ts'))\n",
    "store.to_file(output_file('sgns_procrustes_0.5.store'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, 1.000000000000001, 1.000000000000001, 1.000000000000001,\n",
       "        1.000000000000001, 0.9999952246766742, 0.999999999999999,\n",
       "        0.999999999999999, 0.999999999999999, 0.9999999999999992],\n",
       "       [84, 84, 84, 84, 84, 84, 84, 84, 84, 84]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, 1.0000000000000018, 1.0000000000000018, 1.0000000000000018,\n",
       "        1.0000000000000018, 0.9999903644887552, 0.999999999999999,\n",
       "        0.999999999999999, 0.999999999999999, 0.9999999999999994],\n",
       "       [93, 93, 93, 93, 93, 247, 247, 247, 247, 247]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['in']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding of the unperturbed word 'a' is very stable, i.e., high similarity values, and frequency does not change.\n",
    "The embedding similarity for the perturbed word 'in' drops after the a few time periods and frequency increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally run the change detection on the built time series store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_detection_config = {\n",
    "    'model_file': output_file('sgns_procrustes_0.5.store'),\n",
    "    'tp_file': data_file('changed_vocab'),\n",
    "    'output_file': output_file('result.cd.eval'),\n",
    "    'cd_method': 'cusum_2d',\n",
    "    'store_transformations': {\n",
    "        'measure': 'padcosdist',\n",
    "        'percentual': 'True',\n",
    "        'normalize': 'False'\n",
    "    },\n",
    "    'eval_mode': 'full',\n",
    "    'store_rank_list': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-20 22:21:41,222 : INFO : [CDJ] Prepare store.\n",
      "2019-03-20 22:21:43,328 : INFO : [CDJ] Finished preparing store.\n",
      "2019-03-20 22:21:43,329 : INFO : [CDJ] Init change detection.\n",
      "2019-03-20 22:21:43,330 : INFO : [CDJ] Starting change detection.\n",
      "2019-03-20 22:21:43,331 : INFO : [CDJ] Status 000.0000%\n",
      "2019-03-20 22:21:43,352 : INFO : [CDJ] Status 063.2911%\n",
      "2019-03-20 22:21:43,366 : INFO : [CDJ] Status 100.0000%\n",
      "2019-03-20 22:21:43,383 : INFO : [CDJ] Finished change detection.\n",
      "2019-03-20 22:21:43,385 : INFO : [CDJ] Storing result.\n",
      "2019-03-20 22:21:43,392 : INFO : [CDJ] Finished storing result.\n"
     ]
    }
   ],
   "source": [
    "job = ChangeDetectionJob(change_detection_config)\n",
    "job.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>time</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>6</td>\n",
       "      <td>1.655924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>listened</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unregistered</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>called</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>georgian</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>approximately</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>biased</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  time     score  rank\n",
       "0             in     6  1.655924   1.0\n",
       "1       listened     6  0.000026   2.0\n",
       "2            new     6  0.000020   3.0\n",
       "3   unregistered     6  0.000019   4.0\n",
       "4         called     6  0.000014   5.0\n",
       "5             of     6  0.000012   6.0\n",
       "6       georgian     6  0.000012   7.0\n",
       "7  approximately     6  0.000011   8.0\n",
       "8            and     6  0.000010   9.0\n",
       "9         biased     6  0.000010  10.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(output_file('result.ranked'))\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCAF correctly identifies the the point in time 6 when 'in' semantically changed. The scores also quantify the magnitude of the shift. All other words have only changed slightly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
